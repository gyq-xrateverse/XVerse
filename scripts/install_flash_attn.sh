#!/bin/bash

# Flash-Attention å¿«é€Ÿå®‰è£…è„šæœ¬
set -e

echo "ğŸš€ Flash-Attention å¿«é€Ÿå®‰è£…è„šæœ¬"
echo "======================================"

# æ£€æŸ¥Pythonå’ŒPyTorchç¯å¢ƒ
echo "ğŸ“‹ æ£€æŸ¥ç¯å¢ƒ..."
python --version
echo "PyTorchç‰ˆæœ¬: $(python -c 'import torch; print(torch.__version__)')"
echo "CUDAå¯ç”¨: $(python -c 'import torch; print(torch.cuda.is_available())')"
echo ""

# æ¸…ç†ç¼“å­˜
echo "ğŸ§¹ æ¸…ç†pipç¼“å­˜..."
pip cache purge
echo ""

# é…ç½®æ¸…åæº
echo "âš™ï¸  é…ç½®æ¸…åæº..."
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
pip config set global.trusted-host pypi.tuna.tsinghua.edu.cn
echo "æ¸…åæºé…ç½®å®Œæˆ"
echo ""

# å°è¯•å®‰è£…Flash-Attention (æŒ‰ä¼˜å…ˆçº§é¡ºåº)
echo "âš¡ å¼€å§‹å®‰è£… Flash-Attention..."

# æ–¹æ³•1: VLLMä¼˜åŒ–ç‰ˆ (æœ€æ¨è)
echo "å°è¯•æ–¹æ³•1: VLLMä¼˜åŒ–ç‰ˆ (æ¸…åæº)..."
if pip install --no-cache-dir vllm-flash-attn==2.6.2 -i https://pypi.tuna.tsinghua.edu.cn/simple; then
    echo "âœ… æ–¹æ³•1æˆåŠŸ: VLLMä¼˜åŒ–ç‰ˆå®‰è£…å®Œæˆ"
    INSTALL_SUCCESS=true
else
    echo "âŒ æ–¹æ³•1å¤±è´¥"
    INSTALL_SUCCESS=false
fi

# æ–¹æ³•2: å®˜æ–¹é¢„ç¼–è¯‘ç‰ˆ
if [ "$INSTALL_SUCCESS" = false ]; then
    echo ""
    echo "å°è¯•æ–¹æ³•2: å®˜æ–¹é¢„ç¼–è¯‘ç‰ˆ (æ¸…åæº)..."
    if pip install --no-cache-dir flash-attn==2.6.3 -i https://pypi.tuna.tsinghua.edu.cn/simple; then
        echo "âœ… æ–¹æ³•2æˆåŠŸ: å®˜æ–¹é¢„ç¼–è¯‘ç‰ˆå®‰è£…å®Œæˆ"
        INSTALL_SUCCESS=true
    else
        echo "âŒ æ–¹æ³•2å¤±è´¥"
    fi
fi

# æ–¹æ³•3: æœ€æ–°ç¨³å®šç‰ˆ
if [ "$INSTALL_SUCCESS" = false ]; then
    echo ""
    echo "å°è¯•æ–¹æ³•3: æœ€æ–°ç¨³å®šç‰ˆ (æ¸…åæº)..."
    if pip install --no-cache-dir flash-attn==2.7.4.post1 -i https://pypi.tuna.tsinghua.edu.cn/simple; then
        echo "âœ… æ–¹æ³•3æˆåŠŸ: æœ€æ–°ç¨³å®šç‰ˆå®‰è£…å®Œæˆ"
        INSTALL_SUCCESS=true
    else
        echo "âŒ æ–¹æ³•3å¤±è´¥"
    fi
fi

# æ–¹æ³•4: å¤‡ç”¨å®˜æ–¹æº
if [ "$INSTALL_SUCCESS" = false ]; then
    echo ""
    echo "å°è¯•æ–¹æ³•4: å¤‡ç”¨å®˜æ–¹æº..."
    pip config unset global.index-url
    pip config unset global.trusted-host
    if pip install --no-cache-dir flash-attn==2.6.3 --find-links https://download.pytorch.org/whl/torch_stable.html; then
        echo "âœ… æ–¹æ³•4æˆåŠŸ: å¤‡ç”¨å®˜æ–¹æºå®‰è£…å®Œæˆ"
        INSTALL_SUCCESS=true
    else
        echo "âŒ æ–¹æ³•4å¤±è´¥"
    fi
fi

# éªŒè¯å®‰è£…
echo ""
echo "ğŸ” éªŒè¯å®‰è£…..."
if [ "$INSTALL_SUCCESS" = true ]; then
    if python -c "import flash_attn; print(f'âœ… Flash-Attentionç‰ˆæœ¬: {flash_attn.__version__}')"; then
        echo "ğŸ‰ Flash-Attention å®‰è£…æˆåŠŸå¹¶éªŒè¯é€šè¿‡ï¼"
        echo ""
        echo "ğŸ“ ä¸‹ä¸€æ­¥ï¼š"
        echo "å¯åŠ¨XVerseåº”ç”¨: python run_gradio.py"
    else
        echo "âš ï¸  Flash-Attentionå®‰è£…å®Œæˆä½†å¯¼å…¥éªŒè¯å¤±è´¥"
        echo "é¡¹ç›®ä»å¯æ­£å¸¸è¿è¡Œï¼Œä¼šä½¿ç”¨PyTorchåŸç”Ÿattention"
    fi
else
    echo "âŒ æ‰€æœ‰å®‰è£…æ–¹æ³•éƒ½å¤±è´¥äº†"
    echo ""
    echo "ğŸ’¡ ä¸ç”¨æ‹…å¿ƒï¼é¡¹ç›®å¯ä»¥åœ¨æ²¡æœ‰Flash-Attentionçš„æƒ…å†µä¸‹æ­£å¸¸è¿è¡Œ"
    echo "ä¼šè‡ªåŠ¨å›é€€åˆ°PyTorchåŸç”Ÿattentionï¼Œåªæ˜¯æ€§èƒ½ç¨æ…¢"
    echo ""
    echo "ğŸ”§ æ•…éšœæ’é™¤ï¼š"
    echo "1. æ£€æŸ¥CUDAç‰ˆæœ¬å…¼å®¹æ€§: nvcc --version"
    echo "2. æ£€æŸ¥GPUé©±åŠ¨: nvidia-smi"
    echo "3. å‡çº§pip: pip install --upgrade pip"
fi

echo ""
echo "======================================"
echo "ğŸš€ å®‰è£…è„šæœ¬æ‰§è¡Œå®Œæˆ" 