#!/bin/bash

# Flash-Attention å¿«é€Ÿå®‰è£…è„šæœ¬
# åªå°è¯•æœ€ç¨³å®šçš„é¢„ç¼–è¯‘ç‰ˆæœ¬

echo "ğŸš€ Flash-Attention å¿«é€Ÿå®‰è£…"
echo "=========================="

# æ£€æŸ¥æ˜¯å¦å·²å®‰è£…
echo "æ£€æŸ¥Flash-Attentionå®‰è£…çŠ¶æ€..."
if python -c "import flash_attn; print(f'âœ… å·²å®‰è£… v{flash_attn.__version__}')" 2>/dev/null; then
    echo "Flash-Attentionå·²å®‰è£…ï¼Œæ— éœ€é‡å¤å®‰è£…"
    exit 0
fi

echo "å¼€å§‹å®‰è£…Flash-Attention..."

# æ¸…ç†ç¼“å­˜
echo "æ¸…ç†pipç¼“å­˜..."
pip cache purge

# æ–¹æ³•1: VLLMä¼˜åŒ–ç‰ˆæœ¬ï¼ˆæ¨èï¼‰
echo "å°è¯•å®‰è£…vllm-flash-attn (æ¨èç‰ˆæœ¬)..."
if pip install --no-cache-dir vllm-flash-attn==2.6.2; then
    echo "âœ… vllm-flash-attnå®‰è£…æˆåŠŸ"
    if python -c "import flash_attn; print('æµ‹è¯•é€šè¿‡')" 2>/dev/null; then
        echo "ğŸ‰ Flash-Attentionå®‰è£…å®Œæˆå¹¶æµ‹è¯•é€šè¿‡!"
        exit 0
    fi
fi

# æ–¹æ³•2: å®˜æ–¹é¢„ç¼–è¯‘ç‰ˆæœ¬
echo "å°è¯•å®‰è£…å®˜æ–¹é¢„ç¼–è¯‘ç‰ˆæœ¬..."
if pip install --no-cache-dir flash-attn==2.6.3 --find-links https://download.pytorch.org/whl/torch_stable.html; then
    echo "âœ… å®˜æ–¹ç‰ˆæœ¬å®‰è£…æˆåŠŸ"
    if python -c "import flash_attn; print('æµ‹è¯•é€šè¿‡')" 2>/dev/null; then
        echo "ğŸ‰ Flash-Attentionå®‰è£…å®Œæˆå¹¶æµ‹è¯•é€šè¿‡!"
        exit 0
    fi
fi

# æ–¹æ³•3: æœ€æ–°ç¨³å®šç‰ˆæœ¬
echo "å°è¯•å®‰è£…æœ€æ–°ç¨³å®šç‰ˆæœ¬..."
if pip install --no-cache-dir flash-attn==2.7.4.post1; then
    echo "âœ… æœ€æ–°ç‰ˆæœ¬å®‰è£…æˆåŠŸ"
    if python -c "import flash_attn; print('æµ‹è¯•é€šè¿‡')" 2>/dev/null; then
        echo "ğŸ‰ Flash-Attentionå®‰è£…å®Œæˆå¹¶æµ‹è¯•é€šè¿‡!"
        exit 0
    fi
fi

echo "âŒ æ‰€æœ‰é¢„ç¼–è¯‘ç‰ˆæœ¬å®‰è£…å¤±è´¥"
echo "å»ºè®®:"
echo "1. ä½¿ç”¨å®Œæ•´å®‰è£…è„šæœ¬: bash scripts/install_flash_attn.sh"
echo "2. é¡¹ç›®å¯ä»¥åœ¨æ²¡æœ‰flash-attnçš„æƒ…å†µä¸‹è¿è¡Œï¼ˆä½¿ç”¨PyTorchåŸç”Ÿattentionï¼‰"
exit 1 